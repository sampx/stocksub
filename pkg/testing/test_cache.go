package testing

import (
	"context"
	"crypto/md5"
	"fmt"
	"os"
	"strings"
	"time"

	"stocksub/pkg/provider/tencent"
	"stocksub/pkg/subscriber"
)

type TestDataCache struct {
	storage     *CSVStorage
	memCache    map[string][]subscriber.StockData // L1å†…å­˜ç¼“å­˜
	cacheExpiry time.Duration                     // ç¼“å­˜è¿‡æœŸæ—¶é—´
	dataDir     string                            // æ•°æ®ç›®å½•
	sessionID   string                            // æµ‹è¯•ä¼šè¯ID
}

func NewTestDataCache(dataDir string) *TestDataCache {
	// ç”Ÿæˆæµ‹è¯•ä¼šè¯ID
	sessionID := fmt.Sprintf("test_%d", time.Now().Unix())

	return &TestDataCache{
		storage:     NewCSVStorage(dataDir),
		memCache:    make(map[string][]subscriber.StockData),
		cacheExpiry: 24 * time.Hour, // ç¼“å­˜24å°æ—¶
		dataDir:     dataDir,
		sessionID:   sessionID,
	}
}

// GetStockDataBatch æ™ºèƒ½è·å–è‚¡ç¥¨æ•°æ®ï¼ˆä¸‰å±‚ç¼“å­˜ç­–ç•¥ï¼‰
func (tdc *TestDataCache) GetStockDataBatch(symbols []string) ([]subscriber.StockData, error) {
	cacheKey := tdc.generateCacheKey(symbols)

	// L1: æ£€æŸ¥å†…å­˜ç¼“å­˜
	if cached, exists := tdc.memCache[cacheKey]; exists {
		fmt.Printf("ğŸ¯ ä½¿ç”¨L1å†…å­˜ç¼“å­˜ï¼Œè‚¡ç¥¨: %v\n", symbols)
		return cached, nil
	}

	// L2: æ£€æŸ¥CSVç¼“å­˜
	if cached, err := tdc.loadFromCSVCache(symbols); err == nil && len(cached) == len(symbols) {
		fmt.Printf("ğŸ“ ä½¿ç”¨L2 CSVç¼“å­˜ï¼Œè‚¡ç¥¨: %v\n", symbols)
		tdc.memCache[cacheKey] = cached // æå‡åˆ°L1
		return cached, nil
	}

	// L3: APIè°ƒç”¨ï¼ˆä»…åœ¨å¿…è¦æ—¶ï¼‰
	fmt.Printf("ğŸŒ æ‰§è¡ŒAPIè°ƒç”¨ï¼Œè‚¡ç¥¨: %v\n", symbols)

	// æ£€æŸ¥æ˜¯å¦å¼ºåˆ¶ä½¿ç”¨ç¼“å­˜ï¼ˆCI/CDç¯å¢ƒï¼‰
	if os.Getenv("TEST_FORCE_CACHE") == "1" {
		return nil, fmt.Errorf("å¼ºåˆ¶ç¼“å­˜æ¨¡å¼ï¼Œä½†æœªæ‰¾åˆ°æœ‰æ•ˆç¼“å­˜æ•°æ®")
	}

	provider := tencent.NewProvider()
	// æµ‹è¯•ç¯å¢ƒä¸‹ç¨å¾®å®½æ¾çš„é™æµ
	provider.SetRateLimit(500 * time.Millisecond)
	provider.SetTimeout(30 * time.Second)

	ctx, cancel := context.WithTimeout(context.Background(), 30*time.Second)
	defer cancel()

	results, err := provider.FetchData(ctx, symbols)
	if err != nil {
		return nil, fmt.Errorf("APIè°ƒç”¨å¤±è´¥: %w", err)
	}

	// ä¿å­˜åˆ°CSVç¼“å­˜
	if err := tdc.saveToCSVCache(results); err != nil {
		fmt.Printf("âš ï¸ ä¿å­˜ç¼“å­˜å¤±è´¥: %v\n", err)
	}

	// å­˜å…¥L1ç¼“å­˜
	tdc.memCache[cacheKey] = results

	return results, nil
}

// ForceRefreshCache å¼ºåˆ¶åˆ·æ–°ç¼“å­˜ï¼ˆç”¨äºéœ€è¦æœ€æ–°æ•°æ®çš„æµ‹è¯•ï¼‰
func (tdc *TestDataCache) ForceRefreshCache(symbols []string) ([]subscriber.StockData, error) {
	cacheKey := tdc.generateCacheKey(symbols)
	delete(tdc.memCache, cacheKey) // æ¸…é™¤L1ç¼“å­˜
	// æ¸…é™¤L2ç¼“å­˜çš„é€»è¾‘å¯ä»¥æ ¹æ®éœ€è¦å®ç°
	return tdc.GetStockDataBatch(symbols)
}

// generateCacheKey ç”Ÿæˆç¼“å­˜é”®
func (tdc *TestDataCache) generateCacheKey(symbols []string) string {
	joined := strings.Join(symbols, ",")
	hash := md5.Sum([]byte(joined))
	return fmt.Sprintf("%x", hash[:8]) // ä½¿ç”¨8å­—èŠ‚hashä½œä¸ºé”®
}

// loadFromCSVCache ä»CSVç¼“å­˜åŠ è½½æ•°æ®
func (tdc *TestDataCache) loadFromCSVCache(symbols []string) ([]subscriber.StockData, error) {
	today := time.Now()
	yesterday := today.AddDate(0, 0, -1)

	// å°è¯•åŠ è½½æœ€è¿‘2å¤©çš„ç¼“å­˜æ•°æ®
	dataPoints, err := tdc.storage.ReadDataPoints(yesterday, today)
	if err != nil {
		return nil, err
	}

	// è½¬æ¢ä¸ºStockDataå¹¶ç­›é€‰æ‰€éœ€è‚¡ç¥¨
	symbolSet := make(map[string]bool)
	for _, symbol := range symbols {
		symbolSet[symbol] = true
	}

	var results []subscriber.StockData
	for _, dp := range dataPoints {
		if symbolSet[dp.Symbol] {
			// æ£€æŸ¥ç¼“å­˜æ˜¯å¦è¿‡æœŸ
			if time.Since(dp.Timestamp) > tdc.cacheExpiry {
				continue
			}

			// è½¬æ¢DataPointä¸ºStockData
			var stockData subscriber.StockData
			// ä½¿ç”¨json unmarshalæ¥ä»AllFieldsæ¢å¤å®Œæ•´çš„StockData
			// è¿™æ˜¯ä¸€ä¸ªå‡è®¾ï¼Œå‡è®¾AllFieldså°±æ˜¯StockDataçš„jsonåºåˆ—åŒ–
			// å¦‚æœä¸æ˜¯ï¼Œæˆ‘ä»¬éœ€è¦æ›´å¤æ‚çš„è½¬æ¢é€»è¾‘
			if len(dp.AllFields) > 0 {
				// å‡è®¾AllFieldsçš„ç¬¬ä¸€ä¸ªå…ƒç´ æ˜¯jsonæ•°æ®
				if err := subscriber.UnmarshalStockData([]byte(dp.AllFields[0]), &stockData); err == nil {
					results = append(results, stockData)
					continue
				}
			}

			// å¦‚æœä¸Šé¢çš„æ–¹æ³•å¤±è´¥ï¼Œå›é€€åˆ°æ‰‹åŠ¨æ˜ å°„
			stockData = subscriber.StockData{
				Symbol:    dp.Symbol,
				Price:     dp.Price,
				Timestamp: dp.Timestamp,
				// ... å…¶ä»–å­—æ®µéœ€è¦ä»dp.AllFieldsä¸­è§£æ
			}
			results = append(results, stockData)
		}
	}

	// æ£€æŸ¥æ˜¯å¦æ‰€æœ‰è‚¡ç¥¨éƒ½æœ‰ç¼“å­˜
	if len(results) < len(symbols) {
		return nil, fmt.Errorf("ç¼“å­˜æ•°æ®ä¸å®Œæ•´")
	}

	return results, nil
}

// saveToCSVCache ä¿å­˜æ•°æ®åˆ°CSVç¼“å­˜
func (tdc *TestDataCache) saveToCSVCache(results []subscriber.StockData) error {
	var dataPoints []DataPoint

	now := time.Now()
	for _, result := range results {
		// å°†å®Œæ•´çš„StockDataåºåˆ—åŒ–ä¸ºjsonå¹¶å­˜å‚¨
		jsonData, err := subscriber.MarshalStockData(result)
		if err != nil {
			// è®°å½•é”™è¯¯ä½†ç»§ç»­
			fmt.Printf("åºåˆ—åŒ–StockDataå¤±è´¥: %v\n", err)
			continue
		}

		dp := DataPoint{
			Timestamp:    now,
			Symbol:       result.Symbol,
			QueryTime:    now,
			ResponseTime: now,
			Price:        result.Price,
			Field30:      result.Timestamp.Format("20060102150405"),
			AllFields:    []string{string(jsonData)},
		}
		dataPoints = append(dataPoints, dp)
	}

	return tdc.storage.BatchSaveDataPoints(dataPoints)
}

// GetCacheStats è·å–ç¼“å­˜ç»Ÿè®¡ä¿¡æ¯
func (tdc *TestDataCache) GetCacheStats() map[string]interface{} {
	return map[string]interface{}{
		"session_id":     tdc.sessionID,
		"l1_cache_size":  len(tdc.memCache),
		"cache_expiry":   tdc.cacheExpiry,
		"data_directory": tdc.dataDir,
	}
}

// Close å…³é—­ç¼“å­˜ç®¡ç†å™¨
func (tdc *TestDataCache) Close() error {
	return tdc.storage.Close()
}
