//go:build integration

package integration_test

import (
	"context"
	"encoding/json"
	"fmt"
	"os"
	"os/signal"
	"path/filepath"
	"stocksub/pkg/core"
	"stocksub/pkg/testkit/config"
	"stocksub/pkg/testkit/manager"
	"strings"
	"syscall"
	"testing"
	"time"
)

// TimeFieldAnalysis æ—¶é—´å­—æ®µåˆ†æç»“æœ
type TimeFieldAnalysis struct {
	Symbol    string    `json:"symbol"`
	Market    string    `json:"market"`
	TimeField string    `json:"time_field"`
	Pattern   string    `json:"pattern"`
	Length    int       `json:"length"`
	Timestamp time.Time `json:"timestamp"`
}

// TestSystem_TimeFieldConsistencyLongRun é•¿æ—¶é—´è¿è¡Œçš„æ—¶é—´å­—æ®µæ ¼å¼æ”¶é›†æµ‹è¯•
func TestSystem_TimeFieldConsistencyLongRun(t *testing.T) {
	if os.Getenv("LONG_RUN") != "1" {
		t.Skip("è·³è¿‡é•¿æ—¶é—´è¿è¡Œæµ‹è¯•ï¼Œè®¾ç½® LONG_RUN=1 å¯ç”¨")
	}

	// ä½¿ç”¨æ–°çš„ TestDataManager
	cfg := &config.Config{
		Cache:   config.CacheConfig{Type: "memory"},
		Storage: config.StorageConfig{Type: "csv", Directory: t.TempDir()},
	}
	manager := manager.NewTestDataManager(cfg)
	defer manager.Close()

	// è¿è¡Œå‚æ•°é…ç½®
	runDuration := 4 * time.Hour // é»˜è®¤è¿è¡Œ4å°æ—¶
	if envDuration := os.Getenv("RUN_DURATION"); envDuration != "" {
		if d, err := time.ParseDuration(envDuration); err == nil {
			runDuration = d
		}
	}

	collectInterval := 10 * time.Minute // æ¯10åˆ†é’Ÿæ”¶é›†ä¸€æ¬¡
	if envInterval := os.Getenv("COLLECT_INTERVAL"); envInterval != "" {
		if d, err := time.ParseDuration(envInterval); err == nil {
			collectInterval = d
		}
	}

	t.Logf("ğŸš€ å¯åŠ¨é•¿æ—¶é—´è¿è¡Œæ¨¡å¼: æŒç»­ %vï¼Œæ¯ %v æ”¶é›†ä¸€æ¬¡æ•°æ®", runDuration, collectInterval)

	extendedSamples := map[string][]string{
		"ä¸Šæµ·ä¸»æ¿": {"600000", "600036", "600519", "600887", "601318", "601166"},
		"æ·±åœ³ä¸»æ¿": {"000001", "000002", "000858", "000166", "000725", "002415"},
		"åˆ›ä¸šæ¿":  {"300001", "300750", "300059", "300015", "300124", "300347"},
		"ç§‘åˆ›æ¿":  {"688001", "688036", "688041", "688111", "688169", "688223"},
		"åŒ—äº¤æ‰€":  {"835174", "832000", "430047", "831865", "833533", "872925"},
	}

	var allSymbols []string
	for _, symbols := range extendedSamples {
		allSymbols = append(allSymbols, symbols...)
	}

	startTime := time.Now()
	endTime := startTime.Add(runDuration)
	collectionCount := 0
	allAnalysis := make(map[string][]TimeFieldAnalysis)

	t.Logf("ğŸ“Š å°†æ”¶é›† %d ä¸ªè‚¡ç¥¨åœ¨ %v æ—¶é—´æ®µå†…çš„æ—¶é—´å­—æ®µæ•°æ®", len(allSymbols), runDuration)

	sigChan := make(chan os.Signal, 1)
	signal.Notify(sigChan, syscall.SIGINT, syscall.SIGTERM)
	interrupted := false

	go func() {
		<-sigChan
		t.Logf("âš ï¸ æ¥æ”¶åˆ°åœæ­¢ä¿¡å·ï¼Œå°†åœ¨ä¸‹ä¸€æ¬¡æ•°æ®æ”¶é›†ååœæ­¢å¹¶ç”ŸæˆæŠ¥å‘Š...")
		interrupted = true
	}()

	for time.Now().Before(endTime) && !interrupted {
		collectionCount++
		currentTime := time.Now()
		t.Logf("\nğŸ”„ ç¬¬ %d æ¬¡æ•°æ®æ”¶é›† (%s)", collectionCount, currentTime.Format("15:04:05"))

		// å¼ºåˆ¶åˆ·æ–°ç¼“å­˜ä»¥è·å–çœŸå®APIæ•°æ®
		manager.EnableCache(false)
		results, err := manager.GetStockData(context.Background(), allSymbols)
		manager.EnableCache(true) // ç«‹å³æ¢å¤ç¼“å­˜

		if err != nil {
			t.Logf("âŒ ç¬¬ %d æ¬¡æ”¶é›†å¤±è´¥: %v", collectionCount, err)
		} else {
			t.Logf("âœ… æˆåŠŸè·å– %d ä¸ªè‚¡ç¥¨çš„å®æ—¶æ•°æ®", len(results))
			// åˆ†ææ—¶é—´å­—æ®µæ ¼å¼
			timeFieldAnalysis := analyzeTimeFields(results)

			// ä¿å­˜æœ¬æ¬¡åˆ†æç»“æœ
			timestamp := currentTime.Format("150405")
			allAnalysis[timestamp] = make([]TimeFieldAnalysis, 0, len(timeFieldAnalysis))
			for _, analysis := range timeFieldAnalysis {
				allAnalysis[timestamp] = append(allAnalysis[timestamp], analysis)
			}

			// å®æ—¶ç»Ÿè®¡æ ¼å¼åˆ†å¸ƒ
			formatStats := make(map[string]int)
			for _, analysis := range timeFieldAnalysis {
				formatStats[analysis.Pattern]++
			}

			t.Logf("ğŸ“ˆ æœ¬æ¬¡å‘ç°æ ¼å¼:")
			for pattern, count := range formatStats {
				t.Logf("  %s: %dä¸ªæ ·æœ¬", pattern, count)
			}

			// ä¿å­˜å•æ¬¡åˆ†æç»“æœ
			saveSingleAnalysis(t, timeFieldAnalysis, collectionCount, currentTime)
		}

		// ç­‰å¾…ä¸‹ä¸€æ¬¡æ”¶é›†
		if time.Now().Before(endTime.Add(-collectInterval)) && !interrupted {
			t.Logf("â° ç­‰å¾… %v åè¿›è¡Œä¸‹æ¬¡æ”¶é›†...", collectInterval)

			// åˆ†æ®µç¡çœ ä»¥ä¾¿åŠæ—¶å“åº”ä¿¡å·
			sleepStart := time.Now()
			for time.Since(sleepStart) < collectInterval && !interrupted {
				time.Sleep(1 * time.Second)
			}
		} else {
			break
		}
	}

	if interrupted {
		t.Logf("ğŸ›‘ æµ‹è¯•è¢«æ‰‹åŠ¨åœæ­¢ï¼Œæ­£åœ¨ç”ŸæˆæŠ¥å‘Š...")
	}

	generateLongRunSummaryReport(t, allAnalysis, startTime, time.Now(), collectionCount)

	t.Logf("âœ… é•¿æ—¶é—´è¿è¡Œå®Œæˆï¼Œå…±æ”¶é›† %d æ¬¡æ•°æ®ï¼Œè¿è¡Œæ—¶é•¿ %v",
		collectionCount, time.Since(startTime).Round(time.Second))
}

// saveSingleAnalysis ä¿å­˜å•æ¬¡åˆ†æç»“æœ
func saveSingleAnalysis(t *testing.T, analysis map[string]TimeFieldAnalysis, collectionNum int, timestamp time.Time) {
	outputDir := "data/long_run"
	if err := os.MkdirAll(outputDir, 0755); err != nil {
		t.Logf("âš ï¸ åˆ›å»ºè¾“å‡ºç›®å½•å¤±è´¥: %v", err)
		return
	}

	filename := filepath.Join(outputDir, fmt.Sprintf("collection_%03d_%s.json",
		collectionNum, timestamp.Format("20060102_150405")))

	data, err := json.MarshalIndent(analysis, "", "  ")
	if err != nil {
		t.Logf("âš ï¸ åºåˆ—åŒ–ç¬¬ %d æ¬¡åˆ†æç»“æœå¤±è´¥: %v", collectionNum, err)
		return
	}

	if err := os.WriteFile(filename, data, 0644); err != nil {
		t.Logf("âš ï¸ ä¿å­˜ç¬¬ %d æ¬¡åˆ†æç»“æœå¤±è´¥: %v", collectionNum, err)
	}
}

// generateLongRunSummaryReport ç”Ÿæˆé•¿æ—¶é—´è¿è¡Œçš„æ±‡æ€»æŠ¥å‘Š
func generateLongRunSummaryReport(t *testing.T, allAnalysis map[string][]TimeFieldAnalysis,
	startTime, endTime time.Time, totalCollections int) {

	outputDir := "data/long_run"
	reportFile := filepath.Join(outputDir, fmt.Sprintf("summary_report_%s.md",
		startTime.Format("20060102_150405")))

	var report strings.Builder
	report.WriteString("# é•¿æ—¶é—´è¿è¡Œæ—¶é—´å­—æ®µæ ¼å¼åˆ†ææŠ¥å‘Š\n\n")
	report.WriteString(fmt.Sprintf("**è¿è¡Œæ—¶é—´æ®µ**: %s è‡³ %s\n",
		startTime.Format("2006-01-02 15:04:05"), endTime.Format("2006-01-02 15:04:05")))
	report.WriteString(fmt.Sprintf("**æ€»è¿è¡Œæ—¶é•¿**: %v\n",
		endTime.Sub(startTime).Round(time.Second)))
	report.WriteString(fmt.Sprintf("**æ•°æ®æ”¶é›†æ¬¡æ•°**: %d æ¬¡\n\n", totalCollections))

	overallPatterns := make(map[string]int)
	timeDistribution := make(map[string]map[string]int)              // æ—¶é—´æ®µ -> æ ¼å¼ -> æ•°é‡
	marketTimePatterns := make(map[string]map[string]map[string]int) // å¸‚åœº -> æ—¶é—´ -> æ ¼å¼ -> æ•°é‡

	for timestamp, analyses := range allAnalysis {
		timeDistribution[timestamp] = make(map[string]int)

		for _, analysis := range analyses {
			overallPatterns[analysis.Pattern]++
			timeDistribution[timestamp][analysis.Pattern]++

			if marketTimePatterns[analysis.Market] == nil {
				marketTimePatterns[analysis.Market] = make(map[string]map[string]int)
			}
			if marketTimePatterns[analysis.Market][timestamp] == nil {
				marketTimePatterns[analysis.Market][timestamp] = make(map[string]int)
			}
			marketTimePatterns[analysis.Market][timestamp][analysis.Pattern]++
		}
	}

	report.WriteString("## å‘ç°çš„æ—¶é—´æ ¼å¼æ€»è§ˆ\n\n")
	for pattern, count := range overallPatterns {
		report.WriteString(fmt.Sprintf("- **%s**: %d æ¬¡å‡ºç°\n", pattern, count))
	}

	report.WriteString("\n## ä¸åŒæ—¶é—´æ®µçš„æ ¼å¼åˆ†å¸ƒ\n\n")
	for timestamp, patterns := range timeDistribution {
		report.WriteString(fmt.Sprintf("### %s æ—¶é—´æ®µ\n", timestamp))
		for pattern, count := range patterns {
			report.WriteString(fmt.Sprintf("- %s: %d ä¸ªæ ·æœ¬\n", pattern, count))
		}
		report.WriteString("\n")
	}

	report.WriteString("## æ ¼å¼ä¸€è‡´æ€§åˆ†æ\n\n")
	if len(overallPatterns) == 1 {
		report.WriteString("âœ… **æ ¼å¼å®Œå…¨ä¸€è‡´**: æ‰€æœ‰æ—¶é—´æ®µéƒ½ä½¿ç”¨ç›¸åŒçš„æ—¶é—´æ ¼å¼\n\n")
	} else {
		report.WriteString("âš ï¸ **å‘ç°æ ¼å¼å˜åŒ–**: åœ¨ä¸åŒæ—¶é—´æ®µå‡ºç°äº†ä¸åŒçš„æ—¶é—´æ ¼å¼\n\n")
	}

	report.WriteString("## å»ºè®®\n\n")
	report.WriteString("åŸºäºæœ¬æ¬¡é•¿æ—¶é—´åˆ†æï¼Œå»ºè®®parseTimeå‡½æ•°æ”¯æŒä»¥ä¸‹æ ¼å¼:\n\n")
	for pattern := range overallPatterns {
		switch pattern {
		case "YYYYMMDDHHMMSS":
			report.WriteString("- 14ä½æ ¼å¼: `20060102150405`\n")
		case "YYYYMMDDHHMM":
			report.WriteString("- 12ä½æ ¼å¼: `200601021504`\n")
		case "YYYYMMDDHH":
			report.WriteString("- 10ä½æ ¼å¼: `2006010215`\n")
		case "YYYYMMDD":
			report.WriteString("- 8ä½æ ¼å¼: `20060102`\n")
		}
	}

	if err := os.WriteFile(reportFile, []byte(report.String()), 0644); err != nil {
		t.Logf("âš ï¸ ç”Ÿæˆæ±‡æ€»æŠ¥å‘Šå¤±è´¥: %v", err)
	} else {
		t.Logf("ğŸ“ æ±‡æ€»æŠ¥å‘Šå·²ç”Ÿæˆ: %s", reportFile)
	}
}

// analyzeTimeFields åˆ†æè‚¡ç¥¨æ•°æ®ä¸­çš„æ—¶é—´å­—æ®µæ ¼å¼
func analyzeTimeFields(stocksData []core.StockData) map[string]TimeFieldAnalysis {
	results := make(map[string]TimeFieldAnalysis)

	for _, stock := range stocksData {
		timeField := stock.Timestamp.Format("20060102150405")
		market := determineMarket(stock.Symbol)
		pattern := determineTimePattern(timeField)

		analysis := TimeFieldAnalysis{
			Symbol:    stock.Symbol,
			Market:    market,
			TimeField: timeField,
			Pattern:   pattern,
			Length:    len(timeField),
			Timestamp: time.Now(),
		}

		results[stock.Symbol] = analysis
	}

	return results
}

// determineMarket æ ¹æ®è‚¡ç¥¨ä»£ç ç¡®å®šå¸‚åœº
func determineMarket(symbol string) string {
	if len(symbol) != 6 {
		return "æœªçŸ¥å¸‚åœº"
	}

	switch {
	case strings.HasPrefix(symbol, "6"):
		return "ä¸Šæµ·ä¸»æ¿"
	case strings.HasPrefix(symbol, "688"):
		return "ç§‘åˆ›æ¿"
	case strings.HasPrefix(symbol, "000") || strings.HasPrefix(symbol, "001"):
		return "æ·±åœ³ä¸»æ¿"
	case strings.HasPrefix(symbol, "300"):
		return "åˆ›ä¸šæ¿"
	case strings.HasPrefix(symbol, "43") || strings.HasPrefix(symbol, "83") || strings.HasPrefix(symbol, "87") || strings.HasPrefix(symbol, "920"):
		return "åŒ—äº¤æ‰€"
	default:
		return "å…¶ä»–å¸‚åœº"
	}
}

// determineTimePattern ç¡®å®šæ—¶é—´æ ¼å¼æ¨¡å¼
func determineTimePattern(timeField string) string {
	switch len(timeField) {
	case 14:
		return "YYYYMMDDHHMMSS"
	case 12:
		return "YYYYMMDDHHMM"
	case 10:
		return "YYYYMMDDHH"
	case 8:
		return "YYYYMMDD"
	default:
		return fmt.Sprintf("æœªçŸ¥æ ¼å¼(é•¿åº¦:%d)", len(timeField))
	}
}
